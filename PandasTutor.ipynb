{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmZSmgywjMu7J8BfY4YXYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siripr4/pandas-tutor/blob/main/PandasTutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w8ihLkwdLqRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and run the Ollama API which is available at available at 0.0.0.0:11434\n",
        "!curl https://ollama.ai/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiiyXeqeNeQU",
        "outputId": "e1fde9a2-b77d-4442-8490-588b74ed2030"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 11868    0 11868    0     0  11280      0 --:--:--  0:00:01 --:--:-- 11292>>> Downloading ollama...\n",
            "100 11868    0 11868    0     0  10752      0 --:--:--  0:00:01 --:--:-- 10759\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A script to run the Ollama API in a separate thread so that the notebook's main thread is not blocked"
      ],
      "metadata": {
        "id": "WWpb7qsVRr2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ],
      "metadata": {
        "id": "P2GrxOLtJVF7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model\n",
        "from IPython.display import clear_output\n",
        "!ollama pull llama3.1:8b\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "dV6hDQ7xHpne"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNz7gMzVT0kk",
        "outputId": "73350c60-5b94-4f22-87b1-57020906c0c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ollama)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n",
            "Downloading ollama-0.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, ollama\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 ollama-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "\n",
        "ollama.pull(model='llama3.1:8b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4WeS5VmRpCB",
        "outputId": "5ee93fa7-ed24-4816-e42e-33944584bbf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'success'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated = ollama.generate(model='llama3.1:8b', prompt='42 is the answer to the universe because...')\n",
        "generated['response']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "Wn8S_Y6rV6kR",
        "outputId": "34c1156f-e952-41f5-dd4d-ad58d0a4a86c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A reference to Douglas Adams\\' science fiction series \"The Hitchhiker\\'s Guide to the Galaxy\"!\\n\\nIn the book, a supercomputer named Deep Thought is asked to calculate the \"Answer to the Ultimate Question of Life, the Universe, and Everything.\" After 7.5 million years of computation, Deep Thought finally reveals that the answer is... 42.\\n\\nHowever, it\\'s later revealed that the characters don\\'t actually know what the ultimate question is, so the answer of 42 is essentially meaningless. The number 42 becomes a kind of joke or meme, symbolizing the idea that there might not be a definitive answer to life\\'s greatest mysteries after all!\\n\\nSo, in short, \"42\" is the answer because it was a clever plot device and humorous commentary on our search for meaning in the universe!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-n84_vnFqlr",
        "outputId": "3787c96e-8d46-4a1e-927d-233df97c6ff3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from ollama import AsyncClient\n",
        "\n",
        "async def chat(prompt):\n",
        "  message = {'role': 'user', 'content': prompt}\n",
        "  response = await AsyncClient().chat(model='llama3.1:8b', messages=[message])\n",
        "\n",
        "# Function to handle the chat interaction\n",
        "async def chat_interaction(content):\n",
        "    message = {'role': 'user', 'content': content}\n",
        "    response = await AsyncClient().chat(model='llama3', messages=[message])\n",
        "    return response\n",
        "\n",
        "# Function to abstract the asyncio.run call\n",
        "def run_async(func, *args):\n",
        "    return asyncio.run(func(*args))\n",
        "\n",
        "# asyncio.run(chat('Hello'))\n",
        "user_content = \"Why is the sky blue?\"\n",
        "response = run_async(chat_interaction, user_content)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "uA5UuOviVX-O",
        "outputId": "7951e878-7268-484c-d2a0-44f6e656f8ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-70de4fba9a2f>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# asyncio.run(chat('Hello'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0muser_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Why is the sky blue?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_interaction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-70de4fba9a2f>\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(func, *args)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Function to abstract the asyncio.run call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# asyncio.run(chat('Hello'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add functions to abstract ollama's chat API"
      ],
      "metadata": {
        "id": "tl6JR_9wLFHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from ollama import AsyncClient\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to allow nested use of asyncio.run\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Asynchronous function to handle the chat interaction\n",
        "async def _chat_interaction(content):\n",
        "    message = {'role': 'user', 'content': content}\n",
        "    response = await AsyncClient().chat(model='llama3.1:8b', messages=[message])\n",
        "    return response\n",
        "\n",
        "# Synchronous function to run the asynchronous chat interaction\n",
        "def chat(content):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    if loop.is_running():\n",
        "        # If the event loop is already running, create a new task and wait for it\n",
        "        future = asyncio.ensure_future(_chat_interaction(content))\n",
        "        return loop.run_until_complete(future)\n",
        "    else:\n",
        "        return loop.run_until_complete(_chat_interaction(content))"
      ],
      "metadata": {
        "id": "XnEL3hSqFv5N"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  content = \"Why is the sky blue?\"\n",
        "  response = chat(content)\n",
        "  print(response['message'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtockukbLTjR",
        "outputId": "f0f643b6-c3ff-4d94-d1ce-20f935c8c4c4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': 'assistant', 'content': \"The sky appears blue to us during the day because of a phenomenon called scattering, which involves the interaction between sunlight and the tiny molecules of gases in the atmosphere. Here's a simplified explanation:\\n\\n1. **Sunlight Composition**: Sunlight is made up of all the colors of the rainbow. When sunlight enters Earth's atmosphere, it encounters various particles like nitrogen (N2), oxygen (O2), and water vapor.\\n\\n2. **Scattering Effect**: These particles scatter the light in all directions but do so more efficiently for shorter wavelengths (like blue and violet) than for longer wavelengths (like red and orange). This is known as Rayleigh scattering, named after Lord Rayleigh who first described it in the late 19th century.\\n\\n3. **Perception of Color**: To our eyes on Earth's surface, the scattered blue light reaches us from all directions around the sky, making the sky appear blue. The longer wavelengths like red and orange are less scattered because they travel through the atmosphere more directly to reach our eyes, so we see them as part of the sunset or sunbeams that pierce through the clouds.\\n\\n4. **Variations in Color**: During sunrise and sunset, the sky can take on hues other than blue due to a different combination of atmospheric conditions. The longer wavelengths (like reds) have less opportunity to be scattered because they travel in more direct paths to reach our eyes, so these colors dominate the scene at those times.\\n\\n5. **Atmospheric Conditions**: The color of the sky can also change with various atmospheric conditions such as dust particles, water vapor content, and pollution levels. These can scatter light differently than the clean gases mentioned above, altering the apparent color of the sky.\\n\\nIn summary, the sky's blue appearance is primarily due to the scattering effect of sunlight by the tiny molecules of gases in Earth's atmosphere, which favors shorter wavelengths like blue over longer ones like red.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation"
      ],
      "metadata": {
        "id": "UqkRBofVbFZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Unzip the HTML Files\n",
        "zip_path = 'path_to_your_zip_file.zip'\n",
        "extracted_path = 'extracted_html_files'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "# Step 2: Parse Each HTML File and Generate QA Pairs\n",
        "data = {'question': [], 'answer': []}\n",
        "\n",
        "for root, dirs, files in os.walk(extracted_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.html'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                soup = BeautifulSoup(f, 'html.parser')\n",
        "\n",
        "                # Extract relevant sections\n",
        "                for section in soup.find_all(['section', 'div']):  # Adjust tags as needed\n",
        "                    heading = section.find(['h2', 'h3'])\n",
        "                    if heading:\n",
        "                        content = section.get_text(separator=\"\\n\").strip()\n",
        "\n",
        "                        # \"What is\" questions\n",
        "                        what_question = f\"What is {heading.text}?\"\n",
        "                        data['question'].append(what_question)\n",
        "                        data['answer'].append(content)\n",
        "\n",
        "                        # \"How to\" questions if code snippets are present\n",
        "                        code_snippets = section.find_all('code')\n",
        "                        if code_snippets:\n",
        "                            how_question = f\"How to use {heading.text} in pandas?\"\n",
        "                            how_answer = \"\\n\".join([code.get_text() for code in code_snippets])\n",
        "                            data['question'].append(how_question)\n",
        "                            data['answer'].append(how_answer)\n",
        "\n",
        "# Step 3: Save as QA Pairs\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('pandas_qa_dataset.csv', index=False)\n",
        "\n",
        "print(\"QA pairs have been generated and saved to 'pandas_qa_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1unnO-oCNJz7",
        "outputId": "501bb7d4-9157-40d4-d4ec-3e55b710a7db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': ['What is Constructor#?', 'What is Constructor#?', 'What is Attributes and underlying data#?', 'What is Conversion#?', 'What is Indexing, iteration#?', 'What is Binary operator functions#?', 'What is Function application, GroupBy & window#?', 'What is Computations / descriptive stats#?', 'What is Reindexing / selection / label manipulation#?', 'What is Missing data handling#?', 'What is Reshaping, sorting, transposing#?', 'What is Combining / comparing / joining / merging#?', 'What is Time Series-related#?', 'What is Flags#?', 'What is Metadata#?', 'What is Plotting#?', 'What is Sparse accessor#?', 'What is Serialization / IO / conversion#?'], 'answer': [\"DataFrame\\n#\\n\\n\\n\\n\\nConstructor\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame\\n([data,Â\\xa0index,Â\\xa0columns,Â\\xa0dtype,Â\\xa0copy])\\n\\n\\nTwo-dimensional, size-mutable, potentially heterogeneous tabular data.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAttributes and underlying data\\n#\\n\\n\\nAxes\\n\\n\\n\\n\\n\\n\\nDataFrame.index\\n\\n\\nThe index (row labels) of the DataFrame.\\n\\n\\n\\n\\nDataFrame.columns\\n\\n\\nThe column labels of the DataFrame.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.dtypes\\n\\n\\nReturn the dtypes in the DataFrame.\\n\\n\\n\\n\\nDataFrame.info\\n([verbose,Â\\xa0buf,Â\\xa0max_cols,Â\\xa0...])\\n\\n\\nPrint a concise summary of a DataFrame.\\n\\n\\n\\n\\nDataFrame.select_dtypes\\n([include,Â\\xa0exclude])\\n\\n\\nReturn a subset of the DataFrame's columns based on the column dtypes.\\n\\n\\n\\n\\nDataFrame.values\\n\\n\\nReturn a Numpy representation of the DataFrame.\\n\\n\\n\\n\\nDataFrame.axes\\n\\n\\nReturn a list representing the axes of the DataFrame.\\n\\n\\n\\n\\nDataFrame.ndim\\n\\n\\nReturn an int representing the number of axes / array dimensions.\\n\\n\\n\\n\\nDataFrame.size\\n\\n\\nReturn an int representing the number of elements in this object.\\n\\n\\n\\n\\nDataFrame.shape\\n\\n\\nReturn a tuple representing the dimensionality of the DataFrame.\\n\\n\\n\\n\\nDataFrame.memory_usage\\n([index,Â\\xa0deep])\\n\\n\\nReturn the memory usage of each column in bytes.\\n\\n\\n\\n\\nDataFrame.empty\\n\\n\\nIndicator whether Series/DataFrame is empty.\\n\\n\\n\\n\\nDataFrame.set_flags\\n(*[,Â\\xa0copy,Â\\xa0...])\\n\\n\\nReturn a new object with updated flags.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConversion\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.astype\\n(dtype[,Â\\xa0copy,Â\\xa0errors])\\n\\n\\nCast a pandas object to a specified dtype \\ndtype\\n.\\n\\n\\n\\n\\nDataFrame.convert_dtypes\\n([infer_objects,Â\\xa0...])\\n\\n\\nConvert columns to the best possible dtypes using dtypes supporting \\npd.NA\\n.\\n\\n\\n\\n\\nDataFrame.infer_objects\\n([copy])\\n\\n\\nAttempt to infer better dtypes for object columns.\\n\\n\\n\\n\\nDataFrame.copy\\n([deep])\\n\\n\\nMake a copy of this object's indices and data.\\n\\n\\n\\n\\nDataFrame.bool\\n()\\n\\n\\n(DEPRECATED) Return the bool of a single element Series or DataFrame.\\n\\n\\n\\n\\nDataFrame.to_numpy\\n([dtype,Â\\xa0copy,Â\\xa0na_value])\\n\\n\\nConvert the DataFrame to a NumPy array.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIndexing, iteration\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.head\\n([n])\\n\\n\\nReturn the first \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.at\\n\\n\\nAccess a single value for a row/column label pair.\\n\\n\\n\\n\\nDataFrame.iat\\n\\n\\nAccess a single value for a row/column pair by integer position.\\n\\n\\n\\n\\nDataFrame.loc\\n\\n\\nAccess a group of rows and columns by label(s) or a boolean array.\\n\\n\\n\\n\\nDataFrame.iloc\\n\\n\\n(DEPRECATED) Purely integer-location based indexing for selection by position.\\n\\n\\n\\n\\nDataFrame.insert\\n(loc,Â\\xa0column,Â\\xa0value[,Â\\xa0...])\\n\\n\\nInsert column into DataFrame at specified location.\\n\\n\\n\\n\\nDataFrame.__iter__\\n()\\n\\n\\nIterate over info axis.\\n\\n\\n\\n\\nDataFrame.items\\n()\\n\\n\\nIterate over (column name, Series) pairs.\\n\\n\\n\\n\\nDataFrame.keys\\n()\\n\\n\\nGet the 'info axis' (see Indexing for more).\\n\\n\\n\\n\\nDataFrame.iterrows\\n()\\n\\n\\nIterate over DataFrame rows as (index, Series) pairs.\\n\\n\\n\\n\\nDataFrame.itertuples\\n([index,Â\\xa0name])\\n\\n\\nIterate over DataFrame rows as namedtuples.\\n\\n\\n\\n\\nDataFrame.pop\\n(item)\\n\\n\\nReturn item and drop from frame.\\n\\n\\n\\n\\nDataFrame.tail\\n([n])\\n\\n\\nReturn the last \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.xs\\n(key[,Â\\xa0axis,Â\\xa0level,Â\\xa0drop_level])\\n\\n\\nReturn cross-section from the Series/DataFrame.\\n\\n\\n\\n\\nDataFrame.get\\n(key[,Â\\xa0default])\\n\\n\\nGet item from object for given key (ex: DataFrame column).\\n\\n\\n\\n\\nDataFrame.isin\\n(values)\\n\\n\\nWhether each element in the DataFrame is contained in values.\\n\\n\\n\\n\\nDataFrame.where\\n(cond[,Â\\xa0other,Â\\xa0inplace,Â\\xa0...])\\n\\n\\nReplace values where the condition is False.\\n\\n\\n\\n\\nDataFrame.mask\\n(cond[,Â\\xa0other,Â\\xa0inplace,Â\\xa0axis,Â\\xa0...])\\n\\n\\nReplace values where the condition is True.\\n\\n\\n\\n\\nDataFrame.query\\n(expr,Â\\xa0*[,Â\\xa0inplace])\\n\\n\\nQuery the columns of a DataFrame with a boolean expression.\\n\\n\\n\\n\\n\\n\\n\\n\\nFor more information on \\n.at\\n, \\n.iat\\n, \\n.loc\\n, and\\n\\n.iloc\\n, see the \\nindexing documentation\\n.\\n\\n\\n\\n\\n\\n\\nBinary operator functions\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.__add__\\n(other)\\n\\n\\nGet Addition of DataFrame and other, column-wise.\\n\\n\\n\\n\\nDataFrame.add\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Addition of dataframe and other, element-wise (binary operator \\nadd\\n).\\n\\n\\n\\n\\nDataFrame.sub\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Subtraction of dataframe and other, element-wise (binary operator \\nsub\\n).\\n\\n\\n\\n\\nDataFrame.mul\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Multiplication of dataframe and other, element-wise (binary operator \\nmul\\n).\\n\\n\\n\\n\\nDataFrame.div\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\ntruediv\\n).\\n\\n\\n\\n\\nDataFrame.truediv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\ntruediv\\n).\\n\\n\\n\\n\\nDataFrame.floordiv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Integer division of dataframe and other, element-wise (binary operator \\nfloordiv\\n).\\n\\n\\n\\n\\nDataFrame.mod\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Modulo of dataframe and other, element-wise (binary operator \\nmod\\n).\\n\\n\\n\\n\\nDataFrame.pow\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Exponential power of dataframe and other, element-wise (binary operator \\npow\\n).\\n\\n\\n\\n\\nDataFrame.dot\\n(other)\\n\\n\\nCompute the matrix multiplication between the DataFrame and other.\\n\\n\\n\\n\\nDataFrame.radd\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Addition of dataframe and other, element-wise (binary operator \\nradd\\n).\\n\\n\\n\\n\\nDataFrame.rsub\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Subtraction of dataframe and other, element-wise (binary operator \\nrsub\\n).\\n\\n\\n\\n\\nDataFrame.rmul\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Multiplication of dataframe and other, element-wise (binary operator \\nrmul\\n).\\n\\n\\n\\n\\nDataFrame.rdiv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\nrtruediv\\n).\\n\\n\\n\\n\\nDataFrame.rtruediv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\nrtruediv\\n).\\n\\n\\n\\n\\nDataFrame.rfloordiv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Integer division of dataframe and other, element-wise (binary operator \\nrfloordiv\\n).\\n\\n\\n\\n\\nDataFrame.rmod\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Modulo of dataframe and other, element-wise (binary operator \\nrmod\\n).\\n\\n\\n\\n\\nDataFrame.rpow\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Exponential power of dataframe and other, element-wise (binary operator \\nrpow\\n).\\n\\n\\n\\n\\nDataFrame.lt\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Less than of dataframe and other, element-wise (binary operator \\nlt\\n).\\n\\n\\n\\n\\nDataFrame.gt\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Greater than of dataframe and other, element-wise (binary operator \\ngt\\n).\\n\\n\\n\\n\\nDataFrame.le\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Less than or equal to of dataframe and other, element-wise (binary operator \\nle\\n).\\n\\n\\n\\n\\nDataFrame.ge\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Greater than or equal to of dataframe and other, element-wise (binary operator \\nge\\n).\\n\\n\\n\\n\\nDataFrame.ne\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Not equal to of dataframe and other, element-wise (binary operator \\nne\\n).\\n\\n\\n\\n\\nDataFrame.eq\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Equal to of dataframe and other, element-wise (binary operator \\neq\\n).\\n\\n\\n\\n\\nDataFrame.combine\\n(other,Â\\xa0func[,Â\\xa0fill_value,Â\\xa0...])\\n\\n\\nPerform column-wise combine with another DataFrame.\\n\\n\\n\\n\\nDataFrame.combine_first\\n(other)\\n\\n\\nUpdate null elements with value in the same location in \\nother\\n.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFunction application, GroupBy & window\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.apply\\n(func[,Â\\xa0axis,Â\\xa0raw,Â\\xa0...])\\n\\n\\nApply a function along an axis of the DataFrame.\\n\\n\\n\\n\\nDataFrame.map\\n(func[,Â\\xa0na_action])\\n\\n\\nApply a function to a Dataframe elementwise.\\n\\n\\n\\n\\nDataFrame.applymap\\n(func[,Â\\xa0na_action])\\n\\n\\n(DEPRECATED) Apply a function to a Dataframe elementwise.\\n\\n\\n\\n\\nDataFrame.pipe\\n(func,Â\\xa0*args,Â\\xa0**kwargs)\\n\\n\\nApply chainable functions that expect Series or DataFrames.\\n\\n\\n\\n\\nDataFrame.agg\\n([func,Â\\xa0axis])\\n\\n\\nAggregate using one or more operations over the specified axis.\\n\\n\\n\\n\\nDataFrame.aggregate\\n([func,Â\\xa0axis])\\n\\n\\nAggregate using one or more operations over the specified axis.\\n\\n\\n\\n\\nDataFrame.transform\\n(func[,Â\\xa0axis])\\n\\n\\nCall \\nfunc\\n on self producing a DataFrame with the same axis shape as self.\\n\\n\\n\\n\\nDataFrame.groupby\\n([by,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGroup DataFrame using a mapper or by a Series of columns.\\n\\n\\n\\n\\nDataFrame.rolling\\n(window[,Â\\xa0min_periods,Â\\xa0...])\\n\\n\\nProvide rolling window calculations.\\n\\n\\n\\n\\nDataFrame.expanding\\n([min_periods,Â\\xa0axis,Â\\xa0method])\\n\\n\\nProvide expanding window calculations.\\n\\n\\n\\n\\nDataFrame.ewm\\n([com,Â\\xa0span,Â\\xa0halflife,Â\\xa0alpha,Â\\xa0...])\\n\\n\\nProvide exponentially weighted (EW) calculations.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputations / descriptive stats\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.abs\\n()\\n\\n\\nReturn a Series/DataFrame with absolute numeric value of each element.\\n\\n\\n\\n\\nDataFrame.all\\n([axis,Â\\xa0bool_only,Â\\xa0skipna])\\n\\n\\nReturn whether all elements are True, potentially over an axis.\\n\\n\\n\\n\\nDataFrame.any\\n(*[,Â\\xa0axis,Â\\xa0bool_only,Â\\xa0skipna])\\n\\n\\nReturn whether any element is True, potentially over an axis.\\n\\n\\n\\n\\nDataFrame.clip\\n([lower,Â\\xa0upper,Â\\xa0axis,Â\\xa0inplace])\\n\\n\\nTrim values at input threshold(s).\\n\\n\\n\\n\\nDataFrame.corr\\n([method,Â\\xa0min_periods,Â\\xa0...])\\n\\n\\nCompute pairwise correlation of columns, excluding NA/null values.\\n\\n\\n\\n\\nDataFrame.corrwith\\n(other[,Â\\xa0axis,Â\\xa0drop,Â\\xa0...])\\n\\n\\nCompute pairwise correlation.\\n\\n\\n\\n\\nDataFrame.count\\n([axis,Â\\xa0numeric_only])\\n\\n\\nCount non-NA cells for each column or row.\\n\\n\\n\\n\\nDataFrame.cov\\n([min_periods,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nCompute pairwise covariance of columns, excluding NA/null values.\\n\\n\\n\\n\\nDataFrame.cummax\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative maximum over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.cummin\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative minimum over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.cumprod\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative product over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.cumsum\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative sum over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.describe\\n([percentiles,Â\\xa0include,Â\\xa0...])\\n\\n\\nGenerate descriptive statistics.\\n\\n\\n\\n\\nDataFrame.diff\\n([periods,Â\\xa0axis])\\n\\n\\nFirst discrete difference of element.\\n\\n\\n\\n\\nDataFrame.eval\\n(expr,Â\\xa0*[,Â\\xa0inplace])\\n\\n\\nEvaluate a string describing operations on DataFrame columns.\\n\\n\\n\\n\\nDataFrame.kurt\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased kurtosis over requested axis.\\n\\n\\n\\n\\nDataFrame.kurtosis\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased kurtosis over requested axis.\\n\\n\\n\\n\\nDataFrame.max\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the maximum of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.mean\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the mean of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.median\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the median of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.min\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the minimum of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.mode\\n([axis,Â\\xa0numeric_only,Â\\xa0dropna])\\n\\n\\nGet the mode(s) of each element along the selected axis.\\n\\n\\n\\n\\nDataFrame.pct_change\\n([periods,Â\\xa0fill_method,Â\\xa0...])\\n\\n\\nFractional change between the current and a prior element.\\n\\n\\n\\n\\nDataFrame.prod\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nReturn the product of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.product\\n([axis,Â\\xa0skipna,Â\\xa0...])\\n\\n\\nReturn the product of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.quantile\\n([q,Â\\xa0axis,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nReturn values at the given quantile over requested axis.\\n\\n\\n\\n\\nDataFrame.rank\\n([axis,Â\\xa0method,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nCompute numerical data ranks (1 through n) along axis.\\n\\n\\n\\n\\nDataFrame.round\\n([decimals])\\n\\n\\nRound a DataFrame to a variable number of decimal places.\\n\\n\\n\\n\\nDataFrame.sem\\n([axis,Â\\xa0skipna,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased standard error of the mean over requested axis.\\n\\n\\n\\n\\nDataFrame.skew\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased skew over requested axis.\\n\\n\\n\\n\\nDataFrame.sum\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nReturn the sum of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.std\\n([axis,Â\\xa0skipna,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nReturn sample standard deviation over requested axis.\\n\\n\\n\\n\\nDataFrame.var\\n([axis,Â\\xa0skipna,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased variance over requested axis.\\n\\n\\n\\n\\nDataFrame.nunique\\n([axis,Â\\xa0dropna])\\n\\n\\nCount number of distinct elements in specified axis.\\n\\n\\n\\n\\nDataFrame.value_counts\\n([subset,Â\\xa0normalize,Â\\xa0...])\\n\\n\\nReturn a Series containing the frequency of each distinct row in the Dataframe.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReindexing / selection / label manipulation\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.add_prefix\\n(prefix[,Â\\xa0axis])\\n\\n\\nPrefix labels with string \\nprefix\\n.\\n\\n\\n\\n\\nDataFrame.add_suffix\\n(suffix[,Â\\xa0axis])\\n\\n\\nSuffix labels with string \\nsuffix\\n.\\n\\n\\n\\n\\nDataFrame.align\\n(other[,Â\\xa0join,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nAlign two objects on their axes with the specified join method.\\n\\n\\n\\n\\nDataFrame.at_time\\n(time[,Â\\xa0asof,Â\\xa0axis])\\n\\n\\nSelect values at particular time of day (e.g., 9:30AM).\\n\\n\\n\\n\\nDataFrame.between_time\\n(start_time,Â\\xa0end_time)\\n\\n\\nSelect values between particular times of the day (e.g., 9:00-9:30 AM).\\n\\n\\n\\n\\nDataFrame.drop\\n([labels,Â\\xa0axis,Â\\xa0index,Â\\xa0...])\\n\\n\\nDrop specified labels from rows or columns.\\n\\n\\n\\n\\nDataFrame.drop_duplicates\\n([subset,Â\\xa0keep,Â\\xa0...])\\n\\n\\nReturn DataFrame with duplicate rows removed.\\n\\n\\n\\n\\nDataFrame.duplicated\\n([subset,Â\\xa0keep])\\n\\n\\nReturn boolean Series denoting duplicate rows.\\n\\n\\n\\n\\nDataFrame.equals\\n(other)\\n\\n\\nTest whether two objects contain the same elements.\\n\\n\\n\\n\\nDataFrame.filter\\n([items,Â\\xa0like,Â\\xa0regex,Â\\xa0axis])\\n\\n\\nSubset the dataframe rows or columns according to the specified index labels.\\n\\n\\n\\n\\nDataFrame.first\\n(offset)\\n\\n\\n(DEPRECATED) Select initial periods of time series data based on a date offset.\\n\\n\\n\\n\\nDataFrame.head\\n([n])\\n\\n\\nReturn the first \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.idxmax\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn index of first occurrence of maximum over requested axis.\\n\\n\\n\\n\\nDataFrame.idxmin\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn index of first occurrence of minimum over requested axis.\\n\\n\\n\\n\\nDataFrame.last\\n(offset)\\n\\n\\n(DEPRECATED) Select final periods of time series data based on a date offset.\\n\\n\\n\\n\\nDataFrame.reindex\\n([labels,Â\\xa0index,Â\\xa0columns,Â\\xa0...])\\n\\n\\nConform DataFrame to new index with optional filling logic.\\n\\n\\n\\n\\nDataFrame.reindex_like\\n(other[,Â\\xa0method,Â\\xa0...])\\n\\n\\nReturn an object with matching indices as other object.\\n\\n\\n\\n\\nDataFrame.rename\\n([mapper,Â\\xa0index,Â\\xa0columns,Â\\xa0...])\\n\\n\\nRename columns or index labels.\\n\\n\\n\\n\\nDataFrame.rename_axis\\n([mapper,Â\\xa0index,Â\\xa0...])\\n\\n\\nSet the name of the axis for the index or columns.\\n\\n\\n\\n\\nDataFrame.reset_index\\n([level,Â\\xa0drop,Â\\xa0...])\\n\\n\\nReset the index, or a level of it.\\n\\n\\n\\n\\nDataFrame.sample\\n([n,Â\\xa0frac,Â\\xa0replace,Â\\xa0...])\\n\\n\\nReturn a random sample of items from an axis of object.\\n\\n\\n\\n\\nDataFrame.set_axis\\n(labels,Â\\xa0*[,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nAssign desired index to given axis.\\n\\n\\n\\n\\nDataFrame.set_index\\n(keys,Â\\xa0*[,Â\\xa0drop,Â\\xa0append,Â\\xa0...])\\n\\n\\nSet the DataFrame index using existing columns.\\n\\n\\n\\n\\nDataFrame.tail\\n([n])\\n\\n\\nReturn the last \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.take\\n(indices[,Â\\xa0axis])\\n\\n\\nReturn the elements in the given \\npositional\\n indices along an axis.\\n\\n\\n\\n\\nDataFrame.truncate\\n([before,Â\\xa0after,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nTruncate a Series or DataFrame before and after some index value.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMissing data handling\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.backfill\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0...])\\n\\n\\n(DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap.\\n\\n\\n\\n\\nDataFrame.bfill\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0limit,Â\\xa0...])\\n\\n\\nFill NA/NaN values by using the next valid observation to fill the gap.\\n\\n\\n\\n\\nDataFrame.dropna\\n(*[,Â\\xa0axis,Â\\xa0how,Â\\xa0thresh,Â\\xa0...])\\n\\n\\nRemove missing values.\\n\\n\\n\\n\\nDataFrame.ffill\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0limit,Â\\xa0...])\\n\\n\\nFill NA/NaN values by propagating the last valid observation to next valid.\\n\\n\\n\\n\\nDataFrame.fillna\\n([value,Â\\xa0method,Â\\xa0axis,Â\\xa0...])\\n\\n\\nFill NA/NaN values using the specified method.\\n\\n\\n\\n\\nDataFrame.interpolate\\n([method,Â\\xa0axis,Â\\xa0limit,Â\\xa0...])\\n\\n\\nFill NaN values using an interpolation method.\\n\\n\\n\\n\\nDataFrame.isna\\n()\\n\\n\\nDetect missing values.\\n\\n\\n\\n\\nDataFrame.isnull\\n()\\n\\n\\nDataFrame.isnull is an alias for DataFrame.isna.\\n\\n\\n\\n\\nDataFrame.notna\\n()\\n\\n\\nDetect existing (non-missing) values.\\n\\n\\n\\n\\nDataFrame.notnull\\n()\\n\\n\\nDataFrame.notnull is an alias for DataFrame.notna.\\n\\n\\n\\n\\nDataFrame.pad\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0limit,Â\\xa0...])\\n\\n\\n(DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid.\\n\\n\\n\\n\\nDataFrame.replace\\n([to_replace,Â\\xa0value,Â\\xa0...])\\n\\n\\nReplace values given in \\nto_replace\\n with \\nvalue\\n.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReshaping, sorting, transposing\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.droplevel\\n(level[,Â\\xa0axis])\\n\\n\\nReturn Series/DataFrame with requested index / column level(s) removed.\\n\\n\\n\\n\\nDataFrame.pivot\\n(*,Â\\xa0columns[,Â\\xa0index,Â\\xa0values])\\n\\n\\nReturn reshaped DataFrame organized by given index / column values.\\n\\n\\n\\n\\nDataFrame.pivot_table\\n([values,Â\\xa0index,Â\\xa0...])\\n\\n\\nCreate a spreadsheet-style pivot table as a DataFrame.\\n\\n\\n\\n\\nDataFrame.reorder_levels\\n(order[,Â\\xa0axis])\\n\\n\\nRearrange index levels using input order.\\n\\n\\n\\n\\nDataFrame.sort_values\\n(by,Â\\xa0*[,Â\\xa0axis,Â\\xa0...])\\n\\n\\nSort by the values along either axis.\\n\\n\\n\\n\\nDataFrame.sort_index\\n(*[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nSort object by labels (along an axis).\\n\\n\\n\\n\\nDataFrame.nlargest\\n(n,Â\\xa0columns[,Â\\xa0keep])\\n\\n\\nReturn the first \\nn\\n rows ordered by \\ncolumns\\n in descending order.\\n\\n\\n\\n\\nDataFrame.nsmallest\\n(n,Â\\xa0columns[,Â\\xa0keep])\\n\\n\\nReturn the first \\nn\\n rows ordered by \\ncolumns\\n in ascending order.\\n\\n\\n\\n\\nDataFrame.swaplevel\\n([i,Â\\xa0j,Â\\xa0axis])\\n\\n\\nSwap levels i and j in a \\nMultiIndex\\n.\\n\\n\\n\\n\\nDataFrame.stack\\n([level,Â\\xa0dropna,Â\\xa0sort,Â\\xa0...])\\n\\n\\nStack the prescribed level(s) from columns to index.\\n\\n\\n\\n\\nDataFrame.unstack\\n([level,Â\\xa0fill_value,Â\\xa0sort])\\n\\n\\nPivot a level of the (necessarily hierarchical) index labels.\\n\\n\\n\\n\\nDataFrame.swapaxes\\n(axis1,Â\\xa0axis2[,Â\\xa0copy])\\n\\n\\n(DEPRECATED) Interchange axes and swap values axes appropriately.\\n\\n\\n\\n\\nDataFrame.melt\\n([id_vars,Â\\xa0value_vars,Â\\xa0...])\\n\\n\\nUnpivot a DataFrame from wide to long format, optionally leaving identifiers set.\\n\\n\\n\\n\\nDataFrame.explode\\n(column[,Â\\xa0ignore_index])\\n\\n\\nTransform each element of a list-like to a row, replicating index values.\\n\\n\\n\\n\\nDataFrame.squeeze\\n([axis])\\n\\n\\nSqueeze 1 dimensional axis objects into scalars.\\n\\n\\n\\n\\nDataFrame.to_xarray\\n()\\n\\n\\nReturn an xarray object from the pandas object.\\n\\n\\n\\n\\nDataFrame.T\\n\\n\\nThe transpose of the DataFrame.\\n\\n\\n\\n\\nDataFrame.transpose\\n(*args[,Â\\xa0copy])\\n\\n\\nTranspose index and columns.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCombining / comparing / joining / merging\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.assign\\n(**kwargs)\\n\\n\\nAssign new columns to a DataFrame.\\n\\n\\n\\n\\nDataFrame.compare\\n(other[,Â\\xa0align_axis,Â\\xa0...])\\n\\n\\nCompare to another DataFrame and show the differences.\\n\\n\\n\\n\\nDataFrame.join\\n(other[,Â\\xa0on,Â\\xa0how,Â\\xa0lsuffix,Â\\xa0...])\\n\\n\\nJoin columns of another DataFrame.\\n\\n\\n\\n\\nDataFrame.merge\\n(right[,Â\\xa0how,Â\\xa0on,Â\\xa0left_on,Â\\xa0...])\\n\\n\\nMerge DataFrame or named Series objects with a database-style join.\\n\\n\\n\\n\\nDataFrame.update\\n(other[,Â\\xa0join,Â\\xa0overwrite,Â\\xa0...])\\n\\n\\nModify in place using non-NA values from another DataFrame.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTime Series-related\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.asfreq\\n(freq[,Â\\xa0method,Â\\xa0how,Â\\xa0...])\\n\\n\\nConvert time series to specified frequency.\\n\\n\\n\\n\\nDataFrame.asof\\n(where[,Â\\xa0subset])\\n\\n\\nReturn the last row(s) without any NaNs before \\nwhere\\n.\\n\\n\\n\\n\\nDataFrame.shift\\n([periods,Â\\xa0freq,Â\\xa0axis,Â\\xa0...])\\n\\n\\nShift index by desired number of periods with an optional time \\nfreq\\n.\\n\\n\\n\\n\\nDataFrame.first_valid_index\\n()\\n\\n\\nReturn index for first non-NA value or None, if no non-NA value is found.\\n\\n\\n\\n\\nDataFrame.last_valid_index\\n()\\n\\n\\nReturn index for last non-NA value or None, if no non-NA value is found.\\n\\n\\n\\n\\nDataFrame.resample\\n(rule[,Â\\xa0axis,Â\\xa0closed,Â\\xa0...])\\n\\n\\nResample time-series data.\\n\\n\\n\\n\\nDataFrame.to_period\\n([freq,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nConvert DataFrame from DatetimeIndex to PeriodIndex.\\n\\n\\n\\n\\nDataFrame.to_timestamp\\n([freq,Â\\xa0how,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nCast to DatetimeIndex of timestamps, at \\nbeginning\\n of period.\\n\\n\\n\\n\\nDataFrame.tz_convert\\n(tz[,Â\\xa0axis,Â\\xa0level,Â\\xa0copy])\\n\\n\\nConvert tz-aware axis to target time zone.\\n\\n\\n\\n\\nDataFrame.tz_localize\\n(tz[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nLocalize tz-naive index of a Series or DataFrame to target time zone.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFlags\\n#\\n\\n\\nFlags refer to attributes of the pandas object. Properties of the dataset (like\\nthe date is was recorded, the URL it was accessed from, etc.) should be stored\\nin \\nDataFrame.attrs\\n.\\n\\n\\n\\n\\n\\n\\nFlags\\n(obj,Â\\xa0*,Â\\xa0allows_duplicate_labels)\\n\\n\\nFlags that apply to pandas objects.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMetadata\\n#\\n\\n\\nDataFrame.attrs\\n is a dictionary for storing global metadata for this DataFrame.\\n\\n\\n\\n\\nWarning\\n\\n\\nDataFrame.attrs\\n is considered experimental and may change without warning.\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.attrs\\n\\n\\nDictionary of global attributes of this dataset.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPlotting\\n#\\n\\n\\nDataFrame.plot\\n is both a callable method and a namespace attribute for\\nspecific plotting methods of the form \\nDataFrame.plot.<kind>\\n.\\n\\n\\n\\n\\n\\n\\nDataFrame.plot\\n([x,Â\\xa0y,Â\\xa0kind,Â\\xa0ax,Â\\xa0....])\\n\\n\\nDataFrame plotting accessor and method\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.plot.area\\n([x,Â\\xa0y,Â\\xa0stacked])\\n\\n\\nDraw a stacked area plot.\\n\\n\\n\\n\\nDataFrame.plot.bar\\n([x,Â\\xa0y])\\n\\n\\nVertical bar plot.\\n\\n\\n\\n\\nDataFrame.plot.barh\\n([x,Â\\xa0y])\\n\\n\\nMake a horizontal bar plot.\\n\\n\\n\\n\\nDataFrame.plot.box\\n([by])\\n\\n\\nMake a box plot of the DataFrame columns.\\n\\n\\n\\n\\nDataFrame.plot.density\\n([bw_method,Â\\xa0ind])\\n\\n\\nGenerate Kernel Density Estimate plot using Gaussian kernels.\\n\\n\\n\\n\\nDataFrame.plot.hexbin\\n(x,Â\\xa0y[,Â\\xa0C,Â\\xa0...])\\n\\n\\nGenerate a hexagonal binning plot.\\n\\n\\n\\n\\nDataFrame.plot.hist\\n([by,Â\\xa0bins])\\n\\n\\nDraw one histogram of the DataFrame's columns.\\n\\n\\n\\n\\nDataFrame.plot.kde\\n([bw_method,Â\\xa0ind])\\n\\n\\nGenerate Kernel Density Estimate plot using Gaussian kernels.\\n\\n\\n\\n\\nDataFrame.plot.line\\n([x,Â\\xa0y])\\n\\n\\nPlot Series or DataFrame as lines.\\n\\n\\n\\n\\nDataFrame.plot.pie\\n(**kwargs)\\n\\n\\nGenerate a pie plot.\\n\\n\\n\\n\\nDataFrame.plot.scatter\\n(x,Â\\xa0y[,Â\\xa0s,Â\\xa0c])\\n\\n\\nCreate a scatter plot with varying marker point size and color.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.boxplot\\n([column,Â\\xa0by,Â\\xa0ax,Â\\xa0...])\\n\\n\\nMake a box plot from DataFrame columns.\\n\\n\\n\\n\\nDataFrame.hist\\n([column,Â\\xa0by,Â\\xa0grid,Â\\xa0...])\\n\\n\\nMake a histogram of the DataFrame's columns.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSparse accessor\\n#\\n\\n\\nSparse-dtype specific methods and attributes are provided under the\\n\\nDataFrame.sparse\\n accessor.\\n\\n\\n\\n\\n\\n\\nDataFrame.sparse.density\\n\\n\\nRatio of non-sparse points to total (dense) data points.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.sparse.from_spmatrix\\n(data[,Â\\xa0...])\\n\\n\\nCreate a new DataFrame from a scipy sparse matrix.\\n\\n\\n\\n\\nDataFrame.sparse.to_coo\\n()\\n\\n\\nReturn the contents of the frame as a sparse SciPy COO matrix.\\n\\n\\n\\n\\nDataFrame.sparse.to_dense\\n()\\n\\n\\nConvert a DataFrame with sparse values to dense.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSerialization / IO / conversion\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.from_dict\\n(data[,Â\\xa0orient,Â\\xa0dtype,Â\\xa0...])\\n\\n\\nConstruct DataFrame from dict of array-like or dicts.\\n\\n\\n\\n\\nDataFrame.from_records\\n(data[,Â\\xa0index,Â\\xa0...])\\n\\n\\nConvert structured or record ndarray to DataFrame.\\n\\n\\n\\n\\nDataFrame.to_orc\\n([path,Â\\xa0engine,Â\\xa0index,Â\\xa0...])\\n\\n\\nWrite a DataFrame to the ORC format.\\n\\n\\n\\n\\nDataFrame.to_parquet\\n([path,Â\\xa0engine,Â\\xa0...])\\n\\n\\nWrite a DataFrame to the binary parquet format.\\n\\n\\n\\n\\nDataFrame.to_pickle\\n(path,Â\\xa0*[,Â\\xa0compression,Â\\xa0...])\\n\\n\\nPickle (serialize) object to file.\\n\\n\\n\\n\\nDataFrame.to_csv\\n([path_or_buf,Â\\xa0sep,Â\\xa0na_rep,Â\\xa0...])\\n\\n\\nWrite object to a comma-separated values (csv) file.\\n\\n\\n\\n\\nDataFrame.to_hdf\\n(path_or_buf,Â\\xa0*,Â\\xa0key[,Â\\xa0...])\\n\\n\\nWrite the contained data to an HDF5 file using HDFStore.\\n\\n\\n\\n\\nDataFrame.to_sql\\n(name,Â\\xa0con,Â\\xa0*[,Â\\xa0schema,Â\\xa0...])\\n\\n\\nWrite records stored in a DataFrame to a SQL database.\\n\\n\\n\\n\\nDataFrame.to_dict\\n([orient,Â\\xa0into,Â\\xa0index])\\n\\n\\nConvert the DataFrame to a dictionary.\\n\\n\\n\\n\\nDataFrame.to_excel\\n(excel_writer,Â\\xa0*[,Â\\xa0...])\\n\\n\\nWrite object to an Excel sheet.\\n\\n\\n\\n\\nDataFrame.to_json\\n([path_or_buf,Â\\xa0orient,Â\\xa0...])\\n\\n\\nConvert the object to a JSON string.\\n\\n\\n\\n\\nDataFrame.to_html\\n([buf,Â\\xa0columns,Â\\xa0col_space,Â\\xa0...])\\n\\n\\nRender a DataFrame as an HTML table.\\n\\n\\n\\n\\nDataFrame.to_feather\\n(path,Â\\xa0**kwargs)\\n\\n\\nWrite a DataFrame to the binary Feather format.\\n\\n\\n\\n\\nDataFrame.to_latex\\n([buf,Â\\xa0columns,Â\\xa0header,Â\\xa0...])\\n\\n\\nRender object to a LaTeX tabular, longtable, or nested table.\\n\\n\\n\\n\\nDataFrame.to_stata\\n(path,Â\\xa0*[,Â\\xa0convert_dates,Â\\xa0...])\\n\\n\\nExport DataFrame object to Stata dta format.\\n\\n\\n\\n\\nDataFrame.to_gbq\\n(destination_table,Â\\xa0*[,Â\\xa0...])\\n\\n\\n(DEPRECATED) Write a DataFrame to a Google BigQuery table.\\n\\n\\n\\n\\nDataFrame.to_records\\n([index,Â\\xa0column_dtypes,Â\\xa0...])\\n\\n\\nConvert DataFrame to a NumPy record array.\\n\\n\\n\\n\\nDataFrame.to_string\\n([buf,Â\\xa0columns,Â\\xa0...])\\n\\n\\nRender a DataFrame to a console-friendly tabular output.\\n\\n\\n\\n\\nDataFrame.to_clipboard\\n(*[,Â\\xa0excel,Â\\xa0sep])\\n\\n\\nCopy object to the system clipboard.\\n\\n\\n\\n\\nDataFrame.to_markdown\\n([buf,Â\\xa0mode,Â\\xa0index,Â\\xa0...])\\n\\n\\nPrint DataFrame in Markdown-friendly format.\\n\\n\\n\\n\\nDataFrame.style\\n\\n\\nReturns a Styler object.\\n\\n\\n\\n\\nDataFrame.__dataframe__\\n([nan_as_null,Â\\xa0...])\\n\\n\\nReturn the dataframe interchange object implementing the interchange protocol.\", 'Constructor\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame\\n([data,Â\\xa0index,Â\\xa0columns,Â\\xa0dtype,Â\\xa0copy])\\n\\n\\nTwo-dimensional, size-mutable, potentially heterogeneous tabular data.', \"Attributes and underlying data\\n#\\n\\n\\nAxes\\n\\n\\n\\n\\n\\n\\nDataFrame.index\\n\\n\\nThe index (row labels) of the DataFrame.\\n\\n\\n\\n\\nDataFrame.columns\\n\\n\\nThe column labels of the DataFrame.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.dtypes\\n\\n\\nReturn the dtypes in the DataFrame.\\n\\n\\n\\n\\nDataFrame.info\\n([verbose,Â\\xa0buf,Â\\xa0max_cols,Â\\xa0...])\\n\\n\\nPrint a concise summary of a DataFrame.\\n\\n\\n\\n\\nDataFrame.select_dtypes\\n([include,Â\\xa0exclude])\\n\\n\\nReturn a subset of the DataFrame's columns based on the column dtypes.\\n\\n\\n\\n\\nDataFrame.values\\n\\n\\nReturn a Numpy representation of the DataFrame.\\n\\n\\n\\n\\nDataFrame.axes\\n\\n\\nReturn a list representing the axes of the DataFrame.\\n\\n\\n\\n\\nDataFrame.ndim\\n\\n\\nReturn an int representing the number of axes / array dimensions.\\n\\n\\n\\n\\nDataFrame.size\\n\\n\\nReturn an int representing the number of elements in this object.\\n\\n\\n\\n\\nDataFrame.shape\\n\\n\\nReturn a tuple representing the dimensionality of the DataFrame.\\n\\n\\n\\n\\nDataFrame.memory_usage\\n([index,Â\\xa0deep])\\n\\n\\nReturn the memory usage of each column in bytes.\\n\\n\\n\\n\\nDataFrame.empty\\n\\n\\nIndicator whether Series/DataFrame is empty.\\n\\n\\n\\n\\nDataFrame.set_flags\\n(*[,Â\\xa0copy,Â\\xa0...])\\n\\n\\nReturn a new object with updated flags.\", \"Conversion\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.astype\\n(dtype[,Â\\xa0copy,Â\\xa0errors])\\n\\n\\nCast a pandas object to a specified dtype \\ndtype\\n.\\n\\n\\n\\n\\nDataFrame.convert_dtypes\\n([infer_objects,Â\\xa0...])\\n\\n\\nConvert columns to the best possible dtypes using dtypes supporting \\npd.NA\\n.\\n\\n\\n\\n\\nDataFrame.infer_objects\\n([copy])\\n\\n\\nAttempt to infer better dtypes for object columns.\\n\\n\\n\\n\\nDataFrame.copy\\n([deep])\\n\\n\\nMake a copy of this object's indices and data.\\n\\n\\n\\n\\nDataFrame.bool\\n()\\n\\n\\n(DEPRECATED) Return the bool of a single element Series or DataFrame.\\n\\n\\n\\n\\nDataFrame.to_numpy\\n([dtype,Â\\xa0copy,Â\\xa0na_value])\\n\\n\\nConvert the DataFrame to a NumPy array.\", \"Indexing, iteration\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.head\\n([n])\\n\\n\\nReturn the first \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.at\\n\\n\\nAccess a single value for a row/column label pair.\\n\\n\\n\\n\\nDataFrame.iat\\n\\n\\nAccess a single value for a row/column pair by integer position.\\n\\n\\n\\n\\nDataFrame.loc\\n\\n\\nAccess a group of rows and columns by label(s) or a boolean array.\\n\\n\\n\\n\\nDataFrame.iloc\\n\\n\\n(DEPRECATED) Purely integer-location based indexing for selection by position.\\n\\n\\n\\n\\nDataFrame.insert\\n(loc,Â\\xa0column,Â\\xa0value[,Â\\xa0...])\\n\\n\\nInsert column into DataFrame at specified location.\\n\\n\\n\\n\\nDataFrame.__iter__\\n()\\n\\n\\nIterate over info axis.\\n\\n\\n\\n\\nDataFrame.items\\n()\\n\\n\\nIterate over (column name, Series) pairs.\\n\\n\\n\\n\\nDataFrame.keys\\n()\\n\\n\\nGet the 'info axis' (see Indexing for more).\\n\\n\\n\\n\\nDataFrame.iterrows\\n()\\n\\n\\nIterate over DataFrame rows as (index, Series) pairs.\\n\\n\\n\\n\\nDataFrame.itertuples\\n([index,Â\\xa0name])\\n\\n\\nIterate over DataFrame rows as namedtuples.\\n\\n\\n\\n\\nDataFrame.pop\\n(item)\\n\\n\\nReturn item and drop from frame.\\n\\n\\n\\n\\nDataFrame.tail\\n([n])\\n\\n\\nReturn the last \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.xs\\n(key[,Â\\xa0axis,Â\\xa0level,Â\\xa0drop_level])\\n\\n\\nReturn cross-section from the Series/DataFrame.\\n\\n\\n\\n\\nDataFrame.get\\n(key[,Â\\xa0default])\\n\\n\\nGet item from object for given key (ex: DataFrame column).\\n\\n\\n\\n\\nDataFrame.isin\\n(values)\\n\\n\\nWhether each element in the DataFrame is contained in values.\\n\\n\\n\\n\\nDataFrame.where\\n(cond[,Â\\xa0other,Â\\xa0inplace,Â\\xa0...])\\n\\n\\nReplace values where the condition is False.\\n\\n\\n\\n\\nDataFrame.mask\\n(cond[,Â\\xa0other,Â\\xa0inplace,Â\\xa0axis,Â\\xa0...])\\n\\n\\nReplace values where the condition is True.\\n\\n\\n\\n\\nDataFrame.query\\n(expr,Â\\xa0*[,Â\\xa0inplace])\\n\\n\\nQuery the columns of a DataFrame with a boolean expression.\\n\\n\\n\\n\\n\\n\\n\\n\\nFor more information on \\n.at\\n, \\n.iat\\n, \\n.loc\\n, and\\n\\n.iloc\\n, see the \\nindexing documentation\\n.\", 'Binary operator functions\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.__add__\\n(other)\\n\\n\\nGet Addition of DataFrame and other, column-wise.\\n\\n\\n\\n\\nDataFrame.add\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Addition of dataframe and other, element-wise (binary operator \\nadd\\n).\\n\\n\\n\\n\\nDataFrame.sub\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Subtraction of dataframe and other, element-wise (binary operator \\nsub\\n).\\n\\n\\n\\n\\nDataFrame.mul\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Multiplication of dataframe and other, element-wise (binary operator \\nmul\\n).\\n\\n\\n\\n\\nDataFrame.div\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\ntruediv\\n).\\n\\n\\n\\n\\nDataFrame.truediv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\ntruediv\\n).\\n\\n\\n\\n\\nDataFrame.floordiv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Integer division of dataframe and other, element-wise (binary operator \\nfloordiv\\n).\\n\\n\\n\\n\\nDataFrame.mod\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Modulo of dataframe and other, element-wise (binary operator \\nmod\\n).\\n\\n\\n\\n\\nDataFrame.pow\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Exponential power of dataframe and other, element-wise (binary operator \\npow\\n).\\n\\n\\n\\n\\nDataFrame.dot\\n(other)\\n\\n\\nCompute the matrix multiplication between the DataFrame and other.\\n\\n\\n\\n\\nDataFrame.radd\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Addition of dataframe and other, element-wise (binary operator \\nradd\\n).\\n\\n\\n\\n\\nDataFrame.rsub\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Subtraction of dataframe and other, element-wise (binary operator \\nrsub\\n).\\n\\n\\n\\n\\nDataFrame.rmul\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Multiplication of dataframe and other, element-wise (binary operator \\nrmul\\n).\\n\\n\\n\\n\\nDataFrame.rdiv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\nrtruediv\\n).\\n\\n\\n\\n\\nDataFrame.rtruediv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Floating division of dataframe and other, element-wise (binary operator \\nrtruediv\\n).\\n\\n\\n\\n\\nDataFrame.rfloordiv\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGet Integer division of dataframe and other, element-wise (binary operator \\nrfloordiv\\n).\\n\\n\\n\\n\\nDataFrame.rmod\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Modulo of dataframe and other, element-wise (binary operator \\nrmod\\n).\\n\\n\\n\\n\\nDataFrame.rpow\\n(other[,Â\\xa0axis,Â\\xa0level,Â\\xa0fill_value])\\n\\n\\nGet Exponential power of dataframe and other, element-wise (binary operator \\nrpow\\n).\\n\\n\\n\\n\\nDataFrame.lt\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Less than of dataframe and other, element-wise (binary operator \\nlt\\n).\\n\\n\\n\\n\\nDataFrame.gt\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Greater than of dataframe and other, element-wise (binary operator \\ngt\\n).\\n\\n\\n\\n\\nDataFrame.le\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Less than or equal to of dataframe and other, element-wise (binary operator \\nle\\n).\\n\\n\\n\\n\\nDataFrame.ge\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Greater than or equal to of dataframe and other, element-wise (binary operator \\nge\\n).\\n\\n\\n\\n\\nDataFrame.ne\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Not equal to of dataframe and other, element-wise (binary operator \\nne\\n).\\n\\n\\n\\n\\nDataFrame.eq\\n(other[,Â\\xa0axis,Â\\xa0level])\\n\\n\\nGet Equal to of dataframe and other, element-wise (binary operator \\neq\\n).\\n\\n\\n\\n\\nDataFrame.combine\\n(other,Â\\xa0func[,Â\\xa0fill_value,Â\\xa0...])\\n\\n\\nPerform column-wise combine with another DataFrame.\\n\\n\\n\\n\\nDataFrame.combine_first\\n(other)\\n\\n\\nUpdate null elements with value in the same location in \\nother\\n.', 'Function application, GroupBy & window\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.apply\\n(func[,Â\\xa0axis,Â\\xa0raw,Â\\xa0...])\\n\\n\\nApply a function along an axis of the DataFrame.\\n\\n\\n\\n\\nDataFrame.map\\n(func[,Â\\xa0na_action])\\n\\n\\nApply a function to a Dataframe elementwise.\\n\\n\\n\\n\\nDataFrame.applymap\\n(func[,Â\\xa0na_action])\\n\\n\\n(DEPRECATED) Apply a function to a Dataframe elementwise.\\n\\n\\n\\n\\nDataFrame.pipe\\n(func,Â\\xa0*args,Â\\xa0**kwargs)\\n\\n\\nApply chainable functions that expect Series or DataFrames.\\n\\n\\n\\n\\nDataFrame.agg\\n([func,Â\\xa0axis])\\n\\n\\nAggregate using one or more operations over the specified axis.\\n\\n\\n\\n\\nDataFrame.aggregate\\n([func,Â\\xa0axis])\\n\\n\\nAggregate using one or more operations over the specified axis.\\n\\n\\n\\n\\nDataFrame.transform\\n(func[,Â\\xa0axis])\\n\\n\\nCall \\nfunc\\n on self producing a DataFrame with the same axis shape as self.\\n\\n\\n\\n\\nDataFrame.groupby\\n([by,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nGroup DataFrame using a mapper or by a Series of columns.\\n\\n\\n\\n\\nDataFrame.rolling\\n(window[,Â\\xa0min_periods,Â\\xa0...])\\n\\n\\nProvide rolling window calculations.\\n\\n\\n\\n\\nDataFrame.expanding\\n([min_periods,Â\\xa0axis,Â\\xa0method])\\n\\n\\nProvide expanding window calculations.\\n\\n\\n\\n\\nDataFrame.ewm\\n([com,Â\\xa0span,Â\\xa0halflife,Â\\xa0alpha,Â\\xa0...])\\n\\n\\nProvide exponentially weighted (EW) calculations.', 'Computations / descriptive stats\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.abs\\n()\\n\\n\\nReturn a Series/DataFrame with absolute numeric value of each element.\\n\\n\\n\\n\\nDataFrame.all\\n([axis,Â\\xa0bool_only,Â\\xa0skipna])\\n\\n\\nReturn whether all elements are True, potentially over an axis.\\n\\n\\n\\n\\nDataFrame.any\\n(*[,Â\\xa0axis,Â\\xa0bool_only,Â\\xa0skipna])\\n\\n\\nReturn whether any element is True, potentially over an axis.\\n\\n\\n\\n\\nDataFrame.clip\\n([lower,Â\\xa0upper,Â\\xa0axis,Â\\xa0inplace])\\n\\n\\nTrim values at input threshold(s).\\n\\n\\n\\n\\nDataFrame.corr\\n([method,Â\\xa0min_periods,Â\\xa0...])\\n\\n\\nCompute pairwise correlation of columns, excluding NA/null values.\\n\\n\\n\\n\\nDataFrame.corrwith\\n(other[,Â\\xa0axis,Â\\xa0drop,Â\\xa0...])\\n\\n\\nCompute pairwise correlation.\\n\\n\\n\\n\\nDataFrame.count\\n([axis,Â\\xa0numeric_only])\\n\\n\\nCount non-NA cells for each column or row.\\n\\n\\n\\n\\nDataFrame.cov\\n([min_periods,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nCompute pairwise covariance of columns, excluding NA/null values.\\n\\n\\n\\n\\nDataFrame.cummax\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative maximum over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.cummin\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative minimum over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.cumprod\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative product over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.cumsum\\n([axis,Â\\xa0skipna])\\n\\n\\nReturn cumulative sum over a DataFrame or Series axis.\\n\\n\\n\\n\\nDataFrame.describe\\n([percentiles,Â\\xa0include,Â\\xa0...])\\n\\n\\nGenerate descriptive statistics.\\n\\n\\n\\n\\nDataFrame.diff\\n([periods,Â\\xa0axis])\\n\\n\\nFirst discrete difference of element.\\n\\n\\n\\n\\nDataFrame.eval\\n(expr,Â\\xa0*[,Â\\xa0inplace])\\n\\n\\nEvaluate a string describing operations on DataFrame columns.\\n\\n\\n\\n\\nDataFrame.kurt\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased kurtosis over requested axis.\\n\\n\\n\\n\\nDataFrame.kurtosis\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased kurtosis over requested axis.\\n\\n\\n\\n\\nDataFrame.max\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the maximum of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.mean\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the mean of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.median\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the median of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.min\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn the minimum of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.mode\\n([axis,Â\\xa0numeric_only,Â\\xa0dropna])\\n\\n\\nGet the mode(s) of each element along the selected axis.\\n\\n\\n\\n\\nDataFrame.pct_change\\n([periods,Â\\xa0fill_method,Â\\xa0...])\\n\\n\\nFractional change between the current and a prior element.\\n\\n\\n\\n\\nDataFrame.prod\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nReturn the product of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.product\\n([axis,Â\\xa0skipna,Â\\xa0...])\\n\\n\\nReturn the product of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.quantile\\n([q,Â\\xa0axis,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nReturn values at the given quantile over requested axis.\\n\\n\\n\\n\\nDataFrame.rank\\n([axis,Â\\xa0method,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nCompute numerical data ranks (1 through n) along axis.\\n\\n\\n\\n\\nDataFrame.round\\n([decimals])\\n\\n\\nRound a DataFrame to a variable number of decimal places.\\n\\n\\n\\n\\nDataFrame.sem\\n([axis,Â\\xa0skipna,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased standard error of the mean over requested axis.\\n\\n\\n\\n\\nDataFrame.skew\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased skew over requested axis.\\n\\n\\n\\n\\nDataFrame.sum\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only,Â\\xa0...])\\n\\n\\nReturn the sum of the values over the requested axis.\\n\\n\\n\\n\\nDataFrame.std\\n([axis,Â\\xa0skipna,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nReturn sample standard deviation over requested axis.\\n\\n\\n\\n\\nDataFrame.var\\n([axis,Â\\xa0skipna,Â\\xa0ddof,Â\\xa0numeric_only])\\n\\n\\nReturn unbiased variance over requested axis.\\n\\n\\n\\n\\nDataFrame.nunique\\n([axis,Â\\xa0dropna])\\n\\n\\nCount number of distinct elements in specified axis.\\n\\n\\n\\n\\nDataFrame.value_counts\\n([subset,Â\\xa0normalize,Â\\xa0...])\\n\\n\\nReturn a Series containing the frequency of each distinct row in the Dataframe.', 'Reindexing / selection / label manipulation\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.add_prefix\\n(prefix[,Â\\xa0axis])\\n\\n\\nPrefix labels with string \\nprefix\\n.\\n\\n\\n\\n\\nDataFrame.add_suffix\\n(suffix[,Â\\xa0axis])\\n\\n\\nSuffix labels with string \\nsuffix\\n.\\n\\n\\n\\n\\nDataFrame.align\\n(other[,Â\\xa0join,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nAlign two objects on their axes with the specified join method.\\n\\n\\n\\n\\nDataFrame.at_time\\n(time[,Â\\xa0asof,Â\\xa0axis])\\n\\n\\nSelect values at particular time of day (e.g., 9:30AM).\\n\\n\\n\\n\\nDataFrame.between_time\\n(start_time,Â\\xa0end_time)\\n\\n\\nSelect values between particular times of the day (e.g., 9:00-9:30 AM).\\n\\n\\n\\n\\nDataFrame.drop\\n([labels,Â\\xa0axis,Â\\xa0index,Â\\xa0...])\\n\\n\\nDrop specified labels from rows or columns.\\n\\n\\n\\n\\nDataFrame.drop_duplicates\\n([subset,Â\\xa0keep,Â\\xa0...])\\n\\n\\nReturn DataFrame with duplicate rows removed.\\n\\n\\n\\n\\nDataFrame.duplicated\\n([subset,Â\\xa0keep])\\n\\n\\nReturn boolean Series denoting duplicate rows.\\n\\n\\n\\n\\nDataFrame.equals\\n(other)\\n\\n\\nTest whether two objects contain the same elements.\\n\\n\\n\\n\\nDataFrame.filter\\n([items,Â\\xa0like,Â\\xa0regex,Â\\xa0axis])\\n\\n\\nSubset the dataframe rows or columns according to the specified index labels.\\n\\n\\n\\n\\nDataFrame.first\\n(offset)\\n\\n\\n(DEPRECATED) Select initial periods of time series data based on a date offset.\\n\\n\\n\\n\\nDataFrame.head\\n([n])\\n\\n\\nReturn the first \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.idxmax\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn index of first occurrence of maximum over requested axis.\\n\\n\\n\\n\\nDataFrame.idxmin\\n([axis,Â\\xa0skipna,Â\\xa0numeric_only])\\n\\n\\nReturn index of first occurrence of minimum over requested axis.\\n\\n\\n\\n\\nDataFrame.last\\n(offset)\\n\\n\\n(DEPRECATED) Select final periods of time series data based on a date offset.\\n\\n\\n\\n\\nDataFrame.reindex\\n([labels,Â\\xa0index,Â\\xa0columns,Â\\xa0...])\\n\\n\\nConform DataFrame to new index with optional filling logic.\\n\\n\\n\\n\\nDataFrame.reindex_like\\n(other[,Â\\xa0method,Â\\xa0...])\\n\\n\\nReturn an object with matching indices as other object.\\n\\n\\n\\n\\nDataFrame.rename\\n([mapper,Â\\xa0index,Â\\xa0columns,Â\\xa0...])\\n\\n\\nRename columns or index labels.\\n\\n\\n\\n\\nDataFrame.rename_axis\\n([mapper,Â\\xa0index,Â\\xa0...])\\n\\n\\nSet the name of the axis for the index or columns.\\n\\n\\n\\n\\nDataFrame.reset_index\\n([level,Â\\xa0drop,Â\\xa0...])\\n\\n\\nReset the index, or a level of it.\\n\\n\\n\\n\\nDataFrame.sample\\n([n,Â\\xa0frac,Â\\xa0replace,Â\\xa0...])\\n\\n\\nReturn a random sample of items from an axis of object.\\n\\n\\n\\n\\nDataFrame.set_axis\\n(labels,Â\\xa0*[,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nAssign desired index to given axis.\\n\\n\\n\\n\\nDataFrame.set_index\\n(keys,Â\\xa0*[,Â\\xa0drop,Â\\xa0append,Â\\xa0...])\\n\\n\\nSet the DataFrame index using existing columns.\\n\\n\\n\\n\\nDataFrame.tail\\n([n])\\n\\n\\nReturn the last \\nn\\n rows.\\n\\n\\n\\n\\nDataFrame.take\\n(indices[,Â\\xa0axis])\\n\\n\\nReturn the elements in the given \\npositional\\n indices along an axis.\\n\\n\\n\\n\\nDataFrame.truncate\\n([before,Â\\xa0after,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nTruncate a Series or DataFrame before and after some index value.', 'Missing data handling\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.backfill\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0...])\\n\\n\\n(DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap.\\n\\n\\n\\n\\nDataFrame.bfill\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0limit,Â\\xa0...])\\n\\n\\nFill NA/NaN values by using the next valid observation to fill the gap.\\n\\n\\n\\n\\nDataFrame.dropna\\n(*[,Â\\xa0axis,Â\\xa0how,Â\\xa0thresh,Â\\xa0...])\\n\\n\\nRemove missing values.\\n\\n\\n\\n\\nDataFrame.ffill\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0limit,Â\\xa0...])\\n\\n\\nFill NA/NaN values by propagating the last valid observation to next valid.\\n\\n\\n\\n\\nDataFrame.fillna\\n([value,Â\\xa0method,Â\\xa0axis,Â\\xa0...])\\n\\n\\nFill NA/NaN values using the specified method.\\n\\n\\n\\n\\nDataFrame.interpolate\\n([method,Â\\xa0axis,Â\\xa0limit,Â\\xa0...])\\n\\n\\nFill NaN values using an interpolation method.\\n\\n\\n\\n\\nDataFrame.isna\\n()\\n\\n\\nDetect missing values.\\n\\n\\n\\n\\nDataFrame.isnull\\n()\\n\\n\\nDataFrame.isnull is an alias for DataFrame.isna.\\n\\n\\n\\n\\nDataFrame.notna\\n()\\n\\n\\nDetect existing (non-missing) values.\\n\\n\\n\\n\\nDataFrame.notnull\\n()\\n\\n\\nDataFrame.notnull is an alias for DataFrame.notna.\\n\\n\\n\\n\\nDataFrame.pad\\n(*[,Â\\xa0axis,Â\\xa0inplace,Â\\xa0limit,Â\\xa0...])\\n\\n\\n(DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid.\\n\\n\\n\\n\\nDataFrame.replace\\n([to_replace,Â\\xa0value,Â\\xa0...])\\n\\n\\nReplace values given in \\nto_replace\\n with \\nvalue\\n.', 'Reshaping, sorting, transposing\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.droplevel\\n(level[,Â\\xa0axis])\\n\\n\\nReturn Series/DataFrame with requested index / column level(s) removed.\\n\\n\\n\\n\\nDataFrame.pivot\\n(*,Â\\xa0columns[,Â\\xa0index,Â\\xa0values])\\n\\n\\nReturn reshaped DataFrame organized by given index / column values.\\n\\n\\n\\n\\nDataFrame.pivot_table\\n([values,Â\\xa0index,Â\\xa0...])\\n\\n\\nCreate a spreadsheet-style pivot table as a DataFrame.\\n\\n\\n\\n\\nDataFrame.reorder_levels\\n(order[,Â\\xa0axis])\\n\\n\\nRearrange index levels using input order.\\n\\n\\n\\n\\nDataFrame.sort_values\\n(by,Â\\xa0*[,Â\\xa0axis,Â\\xa0...])\\n\\n\\nSort by the values along either axis.\\n\\n\\n\\n\\nDataFrame.sort_index\\n(*[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nSort object by labels (along an axis).\\n\\n\\n\\n\\nDataFrame.nlargest\\n(n,Â\\xa0columns[,Â\\xa0keep])\\n\\n\\nReturn the first \\nn\\n rows ordered by \\ncolumns\\n in descending order.\\n\\n\\n\\n\\nDataFrame.nsmallest\\n(n,Â\\xa0columns[,Â\\xa0keep])\\n\\n\\nReturn the first \\nn\\n rows ordered by \\ncolumns\\n in ascending order.\\n\\n\\n\\n\\nDataFrame.swaplevel\\n([i,Â\\xa0j,Â\\xa0axis])\\n\\n\\nSwap levels i and j in a \\nMultiIndex\\n.\\n\\n\\n\\n\\nDataFrame.stack\\n([level,Â\\xa0dropna,Â\\xa0sort,Â\\xa0...])\\n\\n\\nStack the prescribed level(s) from columns to index.\\n\\n\\n\\n\\nDataFrame.unstack\\n([level,Â\\xa0fill_value,Â\\xa0sort])\\n\\n\\nPivot a level of the (necessarily hierarchical) index labels.\\n\\n\\n\\n\\nDataFrame.swapaxes\\n(axis1,Â\\xa0axis2[,Â\\xa0copy])\\n\\n\\n(DEPRECATED) Interchange axes and swap values axes appropriately.\\n\\n\\n\\n\\nDataFrame.melt\\n([id_vars,Â\\xa0value_vars,Â\\xa0...])\\n\\n\\nUnpivot a DataFrame from wide to long format, optionally leaving identifiers set.\\n\\n\\n\\n\\nDataFrame.explode\\n(column[,Â\\xa0ignore_index])\\n\\n\\nTransform each element of a list-like to a row, replicating index values.\\n\\n\\n\\n\\nDataFrame.squeeze\\n([axis])\\n\\n\\nSqueeze 1 dimensional axis objects into scalars.\\n\\n\\n\\n\\nDataFrame.to_xarray\\n()\\n\\n\\nReturn an xarray object from the pandas object.\\n\\n\\n\\n\\nDataFrame.T\\n\\n\\nThe transpose of the DataFrame.\\n\\n\\n\\n\\nDataFrame.transpose\\n(*args[,Â\\xa0copy])\\n\\n\\nTranspose index and columns.', 'Combining / comparing / joining / merging\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.assign\\n(**kwargs)\\n\\n\\nAssign new columns to a DataFrame.\\n\\n\\n\\n\\nDataFrame.compare\\n(other[,Â\\xa0align_axis,Â\\xa0...])\\n\\n\\nCompare to another DataFrame and show the differences.\\n\\n\\n\\n\\nDataFrame.join\\n(other[,Â\\xa0on,Â\\xa0how,Â\\xa0lsuffix,Â\\xa0...])\\n\\n\\nJoin columns of another DataFrame.\\n\\n\\n\\n\\nDataFrame.merge\\n(right[,Â\\xa0how,Â\\xa0on,Â\\xa0left_on,Â\\xa0...])\\n\\n\\nMerge DataFrame or named Series objects with a database-style join.\\n\\n\\n\\n\\nDataFrame.update\\n(other[,Â\\xa0join,Â\\xa0overwrite,Â\\xa0...])\\n\\n\\nModify in place using non-NA values from another DataFrame.', 'Time Series-related\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.asfreq\\n(freq[,Â\\xa0method,Â\\xa0how,Â\\xa0...])\\n\\n\\nConvert time series to specified frequency.\\n\\n\\n\\n\\nDataFrame.asof\\n(where[,Â\\xa0subset])\\n\\n\\nReturn the last row(s) without any NaNs before \\nwhere\\n.\\n\\n\\n\\n\\nDataFrame.shift\\n([periods,Â\\xa0freq,Â\\xa0axis,Â\\xa0...])\\n\\n\\nShift index by desired number of periods with an optional time \\nfreq\\n.\\n\\n\\n\\n\\nDataFrame.first_valid_index\\n()\\n\\n\\nReturn index for first non-NA value or None, if no non-NA value is found.\\n\\n\\n\\n\\nDataFrame.last_valid_index\\n()\\n\\n\\nReturn index for last non-NA value or None, if no non-NA value is found.\\n\\n\\n\\n\\nDataFrame.resample\\n(rule[,Â\\xa0axis,Â\\xa0closed,Â\\xa0...])\\n\\n\\nResample time-series data.\\n\\n\\n\\n\\nDataFrame.to_period\\n([freq,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nConvert DataFrame from DatetimeIndex to PeriodIndex.\\n\\n\\n\\n\\nDataFrame.to_timestamp\\n([freq,Â\\xa0how,Â\\xa0axis,Â\\xa0copy])\\n\\n\\nCast to DatetimeIndex of timestamps, at \\nbeginning\\n of period.\\n\\n\\n\\n\\nDataFrame.tz_convert\\n(tz[,Â\\xa0axis,Â\\xa0level,Â\\xa0copy])\\n\\n\\nConvert tz-aware axis to target time zone.\\n\\n\\n\\n\\nDataFrame.tz_localize\\n(tz[,Â\\xa0axis,Â\\xa0level,Â\\xa0...])\\n\\n\\nLocalize tz-naive index of a Series or DataFrame to target time zone.', 'Flags\\n#\\n\\n\\nFlags refer to attributes of the pandas object. Properties of the dataset (like\\nthe date is was recorded, the URL it was accessed from, etc.) should be stored\\nin \\nDataFrame.attrs\\n.\\n\\n\\n\\n\\n\\n\\nFlags\\n(obj,Â\\xa0*,Â\\xa0allows_duplicate_labels)\\n\\n\\nFlags that apply to pandas objects.', 'Metadata\\n#\\n\\n\\nDataFrame.attrs\\n is a dictionary for storing global metadata for this DataFrame.\\n\\n\\n\\n\\nWarning\\n\\n\\nDataFrame.attrs\\n is considered experimental and may change without warning.\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.attrs\\n\\n\\nDictionary of global attributes of this dataset.', \"Plotting\\n#\\n\\n\\nDataFrame.plot\\n is both a callable method and a namespace attribute for\\nspecific plotting methods of the form \\nDataFrame.plot.<kind>\\n.\\n\\n\\n\\n\\n\\n\\nDataFrame.plot\\n([x,Â\\xa0y,Â\\xa0kind,Â\\xa0ax,Â\\xa0....])\\n\\n\\nDataFrame plotting accessor and method\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.plot.area\\n([x,Â\\xa0y,Â\\xa0stacked])\\n\\n\\nDraw a stacked area plot.\\n\\n\\n\\n\\nDataFrame.plot.bar\\n([x,Â\\xa0y])\\n\\n\\nVertical bar plot.\\n\\n\\n\\n\\nDataFrame.plot.barh\\n([x,Â\\xa0y])\\n\\n\\nMake a horizontal bar plot.\\n\\n\\n\\n\\nDataFrame.plot.box\\n([by])\\n\\n\\nMake a box plot of the DataFrame columns.\\n\\n\\n\\n\\nDataFrame.plot.density\\n([bw_method,Â\\xa0ind])\\n\\n\\nGenerate Kernel Density Estimate plot using Gaussian kernels.\\n\\n\\n\\n\\nDataFrame.plot.hexbin\\n(x,Â\\xa0y[,Â\\xa0C,Â\\xa0...])\\n\\n\\nGenerate a hexagonal binning plot.\\n\\n\\n\\n\\nDataFrame.plot.hist\\n([by,Â\\xa0bins])\\n\\n\\nDraw one histogram of the DataFrame's columns.\\n\\n\\n\\n\\nDataFrame.plot.kde\\n([bw_method,Â\\xa0ind])\\n\\n\\nGenerate Kernel Density Estimate plot using Gaussian kernels.\\n\\n\\n\\n\\nDataFrame.plot.line\\n([x,Â\\xa0y])\\n\\n\\nPlot Series or DataFrame as lines.\\n\\n\\n\\n\\nDataFrame.plot.pie\\n(**kwargs)\\n\\n\\nGenerate a pie plot.\\n\\n\\n\\n\\nDataFrame.plot.scatter\\n(x,Â\\xa0y[,Â\\xa0s,Â\\xa0c])\\n\\n\\nCreate a scatter plot with varying marker point size and color.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.boxplot\\n([column,Â\\xa0by,Â\\xa0ax,Â\\xa0...])\\n\\n\\nMake a box plot from DataFrame columns.\\n\\n\\n\\n\\nDataFrame.hist\\n([column,Â\\xa0by,Â\\xa0grid,Â\\xa0...])\\n\\n\\nMake a histogram of the DataFrame's columns.\", 'Sparse accessor\\n#\\n\\n\\nSparse-dtype specific methods and attributes are provided under the\\n\\nDataFrame.sparse\\n accessor.\\n\\n\\n\\n\\n\\n\\nDataFrame.sparse.density\\n\\n\\nRatio of non-sparse points to total (dense) data points.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDataFrame.sparse.from_spmatrix\\n(data[,Â\\xa0...])\\n\\n\\nCreate a new DataFrame from a scipy sparse matrix.\\n\\n\\n\\n\\nDataFrame.sparse.to_coo\\n()\\n\\n\\nReturn the contents of the frame as a sparse SciPy COO matrix.\\n\\n\\n\\n\\nDataFrame.sparse.to_dense\\n()\\n\\n\\nConvert a DataFrame with sparse values to dense.', 'Serialization / IO / conversion\\n#\\n\\n\\n\\n\\n\\n\\nDataFrame.from_dict\\n(data[,Â\\xa0orient,Â\\xa0dtype,Â\\xa0...])\\n\\n\\nConstruct DataFrame from dict of array-like or dicts.\\n\\n\\n\\n\\nDataFrame.from_records\\n(data[,Â\\xa0index,Â\\xa0...])\\n\\n\\nConvert structured or record ndarray to DataFrame.\\n\\n\\n\\n\\nDataFrame.to_orc\\n([path,Â\\xa0engine,Â\\xa0index,Â\\xa0...])\\n\\n\\nWrite a DataFrame to the ORC format.\\n\\n\\n\\n\\nDataFrame.to_parquet\\n([path,Â\\xa0engine,Â\\xa0...])\\n\\n\\nWrite a DataFrame to the binary parquet format.\\n\\n\\n\\n\\nDataFrame.to_pickle\\n(path,Â\\xa0*[,Â\\xa0compression,Â\\xa0...])\\n\\n\\nPickle (serialize) object to file.\\n\\n\\n\\n\\nDataFrame.to_csv\\n([path_or_buf,Â\\xa0sep,Â\\xa0na_rep,Â\\xa0...])\\n\\n\\nWrite object to a comma-separated values (csv) file.\\n\\n\\n\\n\\nDataFrame.to_hdf\\n(path_or_buf,Â\\xa0*,Â\\xa0key[,Â\\xa0...])\\n\\n\\nWrite the contained data to an HDF5 file using HDFStore.\\n\\n\\n\\n\\nDataFrame.to_sql\\n(name,Â\\xa0con,Â\\xa0*[,Â\\xa0schema,Â\\xa0...])\\n\\n\\nWrite records stored in a DataFrame to a SQL database.\\n\\n\\n\\n\\nDataFrame.to_dict\\n([orient,Â\\xa0into,Â\\xa0index])\\n\\n\\nConvert the DataFrame to a dictionary.\\n\\n\\n\\n\\nDataFrame.to_excel\\n(excel_writer,Â\\xa0*[,Â\\xa0...])\\n\\n\\nWrite object to an Excel sheet.\\n\\n\\n\\n\\nDataFrame.to_json\\n([path_or_buf,Â\\xa0orient,Â\\xa0...])\\n\\n\\nConvert the object to a JSON string.\\n\\n\\n\\n\\nDataFrame.to_html\\n([buf,Â\\xa0columns,Â\\xa0col_space,Â\\xa0...])\\n\\n\\nRender a DataFrame as an HTML table.\\n\\n\\n\\n\\nDataFrame.to_feather\\n(path,Â\\xa0**kwargs)\\n\\n\\nWrite a DataFrame to the binary Feather format.\\n\\n\\n\\n\\nDataFrame.to_latex\\n([buf,Â\\xa0columns,Â\\xa0header,Â\\xa0...])\\n\\n\\nRender object to a LaTeX tabular, longtable, or nested table.\\n\\n\\n\\n\\nDataFrame.to_stata\\n(path,Â\\xa0*[,Â\\xa0convert_dates,Â\\xa0...])\\n\\n\\nExport DataFrame object to Stata dta format.\\n\\n\\n\\n\\nDataFrame.to_gbq\\n(destination_table,Â\\xa0*[,Â\\xa0...])\\n\\n\\n(DEPRECATED) Write a DataFrame to a Google BigQuery table.\\n\\n\\n\\n\\nDataFrame.to_records\\n([index,Â\\xa0column_dtypes,Â\\xa0...])\\n\\n\\nConvert DataFrame to a NumPy record array.\\n\\n\\n\\n\\nDataFrame.to_string\\n([buf,Â\\xa0columns,Â\\xa0...])\\n\\n\\nRender a DataFrame to a console-friendly tabular output.\\n\\n\\n\\n\\nDataFrame.to_clipboard\\n(*[,Â\\xa0excel,Â\\xa0sep])\\n\\n\\nCopy object to the system clipboard.\\n\\n\\n\\n\\nDataFrame.to_markdown\\n([buf,Â\\xa0mode,Â\\xa0index,Â\\xa0...])\\n\\n\\nPrint DataFrame in Markdown-friendly format.\\n\\n\\n\\n\\nDataFrame.style\\n\\n\\nReturns a Styler object.\\n\\n\\n\\n\\nDataFrame.__dataframe__\\n([nan_as_null,Â\\xa0...])\\n\\n\\nReturn the dataframe interchange object implementing the interchange protocol.']}\n"
          ]
        }
      ]
    }
  ]
}